{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fbd2595e",
   "metadata": {},
   "source": [
    "# Generate non-empty files of WGS and Imaging dataset of raw, processed and summarised files for 200 patients with 1 sample each. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dbcc00b",
   "metadata": {},
   "source": [
    "## Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4b1c46be",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e54d7a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WGS and Imaging datasets generated successfully\n"
     ]
    }
   ],
   "source": [
    "# Generate the WGS and Imaging datasets\n",
    "num_samples = 200\n",
    "\n",
    "# Base paths\n",
    "wgs_base = \"WGS\"\n",
    "img_base = \"Imaging\"\n",
    "\n",
    "# Folder structures\n",
    "datasets = {\n",
    "    \"WGS\": {\n",
    "        \"base\": wgs_base,\n",
    "        \"suffix\": \"AGRF\",\n",
    "        \"extensions\": [\".fastq\", \".bam\", \".vcf\"]\n",
    "    },\n",
    "    \"Imaging\": {\n",
    "        \"base\": img_base,\n",
    "        \"suffix\": \"CDI\",\n",
    "        \"extensions\": [\".czi\", \".tif\", \".zarr\"]\n",
    "    }\n",
    "}\n",
    "\n",
    "# Size categories\n",
    "categories = [\"KB\", \"1-9MB\", \"10-30MB\"]\n",
    "\n",
    "def assign_category(index, total):\n",
    "    if index < total * 0.25:\n",
    "        return \"KB\"\n",
    "    elif index < total * 0.75:\n",
    "        return \"1-9MB\"\n",
    "    else:\n",
    "        return \"10-30MB\"\n",
    "\n",
    "def base_size_for_category(category):\n",
    "    \"\"\"Base size represents the RAW file size for that sample category.\"\"\"\n",
    "    if category == \"KB\":\n",
    "        return random.randint(10 * 1024, 900 * 1024)\n",
    "    elif category == \"1-9MB\":\n",
    "        return random.randint(1 * 1024 * 1024, 9 * 1024 * 1024)\n",
    "    else:\n",
    "        return random.randint(10 * 1024 * 1024, 30 * 1024 * 1024)\n",
    "\n",
    "def stage_sizes_from_raw(raw_size):\n",
    "    \"\"\"Produce different sizes for Raw / Processed / Summarised \"\"\"\n",
    "    # Processed: 55% - 90% of raw\n",
    "    processed = int(raw_size * random.uniform(0.55, 0.90))\n",
    "\n",
    "    # Summarised: 0.2% - 5% of raw\n",
    "    summarised = int(raw_size * random.uniform(0.002, 0.05))\n",
    "\n",
    "    # Make sure the file is not too small and following the right logic\n",
    "    summarised = max(4 * 1024, summarised)          # at least 4KB\n",
    "    processed = max(summarised + 1024, processed)   # processed > summarised\n",
    "    raw = max(processed + 1024, raw_size)           # raw > processed\n",
    "\n",
    "    return raw, processed, summarised\n",
    "\n",
    "def write_binary_file(path, size_bytes, chunk_size=1024 * 1024):\n",
    "    remaining = size_bytes\n",
    "    with open(path, \"wb\") as f:\n",
    "        while remaining > 0:\n",
    "            chunk = min(chunk_size, remaining)\n",
    "            f.write(os.urandom(chunk))\n",
    "            remaining -= chunk\n",
    "\n",
    "# Create folders\n",
    "for ds in datasets.values():\n",
    "    for sub in [\"Raw\", \"Processed\", \"Summarised\"]:\n",
    "        os.makedirs(os.path.join(ds[\"base\"], sub), exist_ok=True)\n",
    "\n",
    "# Generate data\n",
    "for i in range(num_samples):\n",
    "    category = assign_category(i, num_samples)\n",
    "\n",
    "    # Choose a base RAW size per sample \n",
    "    raw_size = base_size_for_category(category)\n",
    "\n",
    "    # Derive different sizes for each stage\n",
    "    raw_bytes, processed_bytes, summarised_bytes = stage_sizes_from_raw(raw_size)\n",
    "\n",
    "    for name, ds in datasets.items():\n",
    "        sample_id = f\"XY{i+1:03d}-{ds['suffix']}\"\n",
    "        paths_and_sizes = [\n",
    "            (os.path.join(ds[\"base\"], \"Raw\", f\"{sample_id}{ds['extensions'][0]}\"), raw_bytes),\n",
    "            (os.path.join(ds[\"base\"], \"Processed\", f\"{sample_id}{ds['extensions'][1]}\"), processed_bytes),\n",
    "            (os.path.join(ds[\"base\"], \"Summarised\", f\"{sample_id}{ds['extensions'][2]}\"), summarised_bytes),\n",
    "        ]\n",
    "\n",
    "        for path, size_bytes in paths_and_sizes:\n",
    "            write_binary_file(path, size_bytes)\n",
    "\n",
    "print(\"WGS and Imaging datasets generated successfully\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d711f1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV file created: patient_sample_mapping.csv\n"
     ]
    }
   ],
   "source": [
    "#Create a csv file to map the patientid to the sampleid\n",
    "import csv\n",
    "\n",
    "output_csv = \"patient_sample_mapping.csv\"\n",
    "\n",
    "with open(output_csv, \"w\", newline=\"\") as f:\n",
    "    writer = csv.writer(f)\n",
    "    \n",
    "    # Header\n",
    "    writer.writerow([\"PatientID\", \"WGS_SampleID\", \"Imaging_SampleID\"])\n",
    "    \n",
    "    # Rows\n",
    "    for i in range(1, num_samples + 1):\n",
    "        patient_id =  f\"PatientID{i:03d}_DiseaseX\"\n",
    "        wgs_sample_id = f\"XY{i:03d}-AGRF\"\n",
    "        imaging_sample_id = f\"XY{i:03d}-CDI\"\n",
    "        \n",
    "        writer.writerow([patient_id, wgs_sample_id, imaging_sample_id])\n",
    "\n",
    "print(\"CSV file created:\", output_csv)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "568755c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imaging folder zipped successfully.\n"
     ]
    }
   ],
   "source": [
    "#Zip the Imaging output datafiles\n",
    "import shutil\n",
    "\n",
    "# Folder to zip\n",
    "folder_to_zip = \"Imaging\"\n",
    "\n",
    "# Output zip file name \n",
    "output_zip = \"Imaging\"\n",
    "\n",
    "# Create the zip\n",
    "shutil.make_archive(output_zip, \"zip\", folder_to_zip)\n",
    "\n",
    "print(\"Imaging folder zipped successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bfb8c0f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WGS folder zipped successfully.\n"
     ]
    }
   ],
   "source": [
    "#Zip the WGS output datafiles\n",
    "import shutil\n",
    "\n",
    "# Folder to zip\n",
    "folder_to_zip = \"WGS\"\n",
    "\n",
    "# Output zip file name \n",
    "output_zip = \"WGS\"\n",
    "\n",
    "# Create the zip\n",
    "shutil.make_archive(output_zip, \"zip\", folder_to_zip)\n",
    "\n",
    "print(\"WGS folder zipped successfully.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
